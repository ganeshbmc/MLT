{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Artificial Neural Networks  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Import libraries**  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "seed = 42\n",
    "rng = np.random.default_rng(seed=seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network Class  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We shall start writing the `Network Class`. The two methods that are indispensible for any ML class are:  \n",
    "\n",
    "* `fit`  \n",
    "* `predict`  \n",
    "\n",
    "Fitting a neural network model requires us to compute two passes on the data:  \n",
    "\n",
    "* `forward`  \n",
    "* `backward`  \n",
    "\n",
    "We need to start at some place by initializing the network and various hyperparameters and this requires an `init` method:  \n",
    "\n",
    "* `init`  \n",
    "\n",
    "In most of these methods, we would have to take help of certain `helper` functions:  \n",
    "\n",
    "* `activations`  \n",
    "* `losses`  \n",
    "\n",
    "This is the process but we will work through it in reverse order so that each step of the process does not have any forward references:  \n",
    "\n",
    "* `helpers` --> `init` --> `forward` --> `backward` --> `fit` --> `predict`  \n",
    "\n",
    "The skeleton of the class is given in the code block below. For ease of exposition, we are going to discuss the methods one at a time and then plug them into the class right at the end.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Skeleton of Network Class  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network:\n",
    "\n",
    "    def init(self, layers, activation_choice = 'relu',\n",
    "                        output_choice = 'softmax',\n",
    "                        loss_choice = 'cce'):\n",
    "        pass\n",
    "\n",
    "    def forward(self, X):\n",
    "        pass\n",
    "\n",
    "    def backward(self, Y, Y_hat):\n",
    "        pass\n",
    "\n",
    "    def fit(self, X, lr = 0.01,\n",
    "                    epochs = 100,\n",
    "                    batch_size = 100):\n",
    "        pass\n",
    "\n",
    "    def predict(self, X):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Activation functions  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hidden layer  \n",
    "\n",
    "We will look at two activation functions for the hidden layers. Both these functions will be applied element-wise. The input to these functions can be scalars, vectors or matrices.  \n",
    "\n",
    "* `Sigmoid`  \n",
    "* `ReLU`  \n",
    "\n",
    "We also need the derivatives of these functions while computing the backward pass. Deriving the mathematical expressions for them are left as an exercise to the learners.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "def grad_sigmoid(z):\n",
    "    return sigmoid(z) * (1 - sigmoid(z))\n",
    "\n",
    "def relu(z):\n",
    "    return np.where(z >= 0, z, 0)\n",
    "\n",
    "def grad_relu(z):\n",
    "    return np.where(z >= 0, 1, 0)\n",
    "\n",
    "# A dictionary of activation functions will be used while initializing the network  \n",
    "hidden_act = {'sigmoid': sigmoid, 'relu': relu}\n",
    "grad_hidden_act = {'sigmoid': grad_sigmoid, 'relu': grad_relu}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output layer  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will look at the two activation functions for the output layer.  \n",
    "\n",
    "* `Identity` for regression  \n",
    "* `Softmax` for classification  \n",
    "\n",
    "**Note**: In softmax, to avoid overflow, we will subtract the row-wise maximum from each row while computing the softmax.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def identity(z):\n",
    "    return z\n",
    "\n",
    "def softmax(z):\n",
    "    '''Row-wise softmax'''\n",
    "    # Check if z is a matrix\n",
    "    assert z.ndim == 2\n",
    "    \n",
    "    # To prevent overflow, subtract softmax row-wise\n",
    "    z -= z.max(axis=1, keepdims=True)\n",
    "\n",
    "    # Compute row-wise softmax\n",
    "    prob = np.exp(z) / np.exp(z).sum(axis=1, keepdims=True)\n",
    "\n",
    "    # Check if the row probability is a probability distribution\n",
    "    assert np.allclose(prob.sum(axis=1), np.ones(z.shape[0]))\n",
    "    return prob\n",
    "\n",
    "output_act = {'softmax': softmax, 'identity': identity}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two types of losses we will use:  \n",
    "\n",
    "* `Least square error` for regression  \n",
    "* `Categorical cross-entropy` loss for classification  \n",
    "\n",
    "[video link](https://youtu.be/q1GTG13OgNY?t=345)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def least_square(y, y_hat):\n",
    "    return 0.5 * np.sum((y_hat - y) * (y_hat - y))\n",
    "    # e = y_hat - y\n",
    "    # return (e.T @ e)\n",
    "\n",
    "def cce(Y, Y_hat):      # Note that capital Y is used to denote that Y is a matrix with shape n*k\n",
    "    return -np.sum(Y * np.log(Y_hat))\n",
    "\n",
    "losses = {'least_square': least_square, 'cce': cce}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we will look at two parts:  \n",
    "\n",
    "* Network architecture  \n",
    "* Weight initialization  \n",
    "\n",
    "`Network architecture`  \n",
    "\n",
    "The following components mainly determine the structure of the network:  \n",
    "* number of layers  \n",
    "* number of neurons per layer  \n",
    "\n",
    "We will use `l` to index the layers. The network has `L` layers in all.  \n",
    "\n",
    "* `l = 0`: Input layer  \n",
    "* `1 <= l <= L -1`: Hidden layers  \n",
    "* `l = L`: Output layer  \n",
    "\n",
    "We shall represent the number of layers and the neurons using a list `layers`. The variable L will never make an explicit appearance anywhere, instead we will use `range(len(layers))` to iterate through the layers.  \n",
    "\n",
    "One useful task is to compute the total number of parameters in the network. This will come in handy later on.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_params(layers):\n",
    "    num_params = 0\n",
    "    for l in range(1, len(layers)):\n",
    "        num_weights = layers[l-1] * layers[l]\n",
    "        num_biases = layers[l]\n",
    "        num_params += (num_weights + num_biases)\n",
    "    return num_params\n",
    "\n",
    "# Test count_params  \n",
    "assert count_params([64, 5, 10]) == (64 * 5 + 5) + (5 * 10 + 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Parameter initialization`  \n",
    "\n",
    "The weight-matrix at layer `l` has size `layers[l-1] * layers[l]`. The bias at layer `l` is a vector of size `layers[l]`. We will store all these weights in a list `w` of the same size as `layers`. `W[l]` would correspond to `Wl`. Since there are `L` weight matrices, `w[0]` would be set to `None`. Recall that the size of the list is `L + 1`. A similar list would be required for `b`.  \n",
    "\n",
    "To mke the gradient descent update simpler, it will be useful to have a master vector, `θ`, that has a **reference** to all the parameters in the network. We will do the same for the gradients `θ(g)`. So, whenever `θ` is updated, the weights `Wl` will also be updated and vice-versa.  \n",
    "\n",
    "One way to do this is to first start with the master vector and then reshape chunks of it into the dimensions of a weight matrix. Reshaping an array usually returns a view of an array and not a copy. To understand this function better, refer to NumPy's documentation on [**Copies and Views**](https://numpy.org/doc/stable/user/basics.copies.html).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_params(layers):\n",
    "    num_params = count_params(layers)               # number of parameters in the network\n",
    "\n",
    "    W = [None for _ in range(len(layers))]          # weights\n",
    "    b = [None for _ in range(len(layers))]          # biases\n",
    "    gW = [None for _ in range(len(layers))]         # gradient of loss w.r.t weights\n",
    "    gb = [None for _ in range(len(layers))]         # gradient of loss w.r.t biases\n",
    "\n",
    "    # Sample from N(0,1) to initialize the params\n",
    "    theta = rng.standard_normal(num_params)         # master params\n",
    "    gtheta = np.zeros(num_params)                   # master gradients\n",
    "\n",
    "    # (start, end) specify the portion of the theta\n",
    "    # that corresponds to the parameter, W_l or b_l\n",
    "    start, end = 0, 0\n",
    "    for l in range(1, len(layers)):\n",
    "        # Reshape the section (start, end) and assign it to W[l]\n",
    "        end = start + layers[l-1] * layers[l]\n",
    "        W[l] = theta[start: end].reshape(layers[l-1], layers[l])\n",
    "        gW[l] = gtheta[start: end].reshape(layers[l-1], layers[l])\n",
    "        # Reshape the section (start, end) and assign it to b[l]\n",
    "        start, end = end, end + layers[l]\n",
    "        b[l] = theta[start: end].reshape(layers[l])\n",
    "        gb[l] = gtheta[start: end].reshape(layers[l])\n",
    "        start = end\n",
    "\n",
    "    return theta, gtheta, W, b, gW, gb\n",
    "\n",
    "### Test init_params\n",
    "layers = [64, 32, 10]\n",
    "params = init_params([64, 32, 10])\n",
    "for l in range(1, len(layers)):\n",
    "    # check if the weights are views of the master vector\n",
    "    assert params[2][l].base is params[0]\n",
    "    assert params[3][l].base is params[0]\n",
    "    assert params[4][l].base is params[1]\n",
    "    assert params[5][l].base is params[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are now ready to initialize the network.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init(self, layers, activation_choice='relu',\n",
    "                        output_choice='softmax',\n",
    "                        loss_choice = 'cce'):\n",
    "    self.layers = layers\n",
    "\n",
    "    # Parameters and gradients\n",
    "    self.theta, self.gtheta,\\\n",
    "    self.W, self.b,\\\n",
    "    self.gW, self.gb = init_params(layers)\n",
    "\n",
    "    # Activation functions\n",
    "    self.ghid = hidden_act[activation_choice]\n",
    "    self.grad_ghid = grad_hidden_act[activation_choice]\n",
    "    self.gout = output_act[output_choice]\n",
    "\n",
    "    # Loss  \n",
    "    self.loss = losses[loss_choice]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forward pass  \n",
    "\n",
    "[video link](https://youtu.be/q1GTG13OgNY?t=929)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(self, X):\n",
    "    self.Z = [None for _ in range(len(self.layers))]\n",
    "    self.A = [None for _ in range(len(self.layers))]\n",
    "    self.A[0] = X\n",
    "    self.Z[0] = X\n",
    "\n",
    "    for l in range(1, len(self.layers)):\n",
    "        self.Z[l] = self.A[l-1] @ self.W[l] + self.b[l]\n",
    "        self.A[l] = self.ghid(self.Z[l])\n",
    "\n",
    "    self.A[-1] = self.gout(self.Z[-1])\n",
    "    return self.A[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Backward pass  \n",
    "\n",
    "[video link](https://youtu.be/q1GTG13OgNY?t=980)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward(self, Y, Y_hat):\n",
    "    gZ = [None for _ in range(len(self.layers))]\n",
    "    gA = [None for _ in range(len(self.layers))]\n",
    "    gZ[-1] = Y_hat - Y\n",
    "\n",
    "    for l in range(len(self.layers) - 1, 0, -1):\n",
    "        self.gW[l][:, :] = self.A[l-1].T @ gZ[l]\n",
    "        self.gb[l][:] = np.sum(gZ[l].T, axis = 1)\n",
    "        gA[l-1] = gZ[l] @ self.W[l].T\n",
    "        gZ[l-1] = gA[l-1] * self.grad_ghid(self.Z[l-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An important point to note is the use of `self.gW[l][:, :]` while updating the weights and not `self.gW[l]`.  \n",
    "`self.gW[l][:, :]` does in-place update, thus maintaining a link with master params, namely `self.theta`.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit  \n",
    "\n",
    "We now have all the ingredients to fit a model using gradient descent. We will use mini-batch gradient descent. The batch-size, learning rate and number of epochs will be hyperparameters.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(self, X, Y, lr = 0.01,\n",
    "                    epochs = 100,\n",
    "                    batch_size = 100):\n",
    "    self.losses = []\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        # Compute the loss \n",
    "        Y_hat = self.forward(X)\n",
    "        self.losses.append(self.loss(Y, Y_hat))\n",
    "        # Shuffle the dataset\n",
    "        indices = np.arange(X.shape[0])\n",
    "        # Use rng.shuffle to maintain reproducibility\n",
    "        rng.shuffle(indices)\n",
    "        X, Y = X[indices], Y[indices]\n",
    "        # Number of batches\n",
    "        num_batches = X.shape[0] // batch_size\n",
    "        # Mini-batch GD\n",
    "        for b in range(num_batches):\n",
    "            Xb = X[b * batch_size: (b + 1) * batch_size]\n",
    "            Yb = Y[b * batch_size: (b + 1) * batch_size]\n",
    "            # Compute the predictions for this batch\n",
    "            Y_hat_b = self.forward(Xb)\n",
    "            # Compute the gradients for this batch\n",
    "            self.backward(Yb, Y_hat_b)\n",
    "            # Update the gradients of all parameters\n",
    "            # -= is used for in-place update\n",
    "            self.theta -= lr * self.gtheta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict  \n",
    "\n",
    "Finally, we can use the trained model to predict the labels.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(self, X):\n",
    "    Y_hat = self.forward(X)\n",
    "    # regression\n",
    "    if X.shape[-1] == 1:\n",
    "        return Y_hat\n",
    "    # classification\n",
    "    else:\n",
    "        return np.argmax(Y_hat, axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plugging in  \n",
    "\n",
    "We can now plug all of this into our class.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "Network.__init__ = init\n",
    "Network.forward = forward\n",
    "Network.backward = backward\n",
    "Network.fit = fit\n",
    "Network.predict = predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data  \n",
    "\n",
    "We will import the digits dataset from `sklearn`.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample image with label 0\n",
      "(1797, 8, 8)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_digits\n",
    "digits = load_digits()\n",
    "\n",
    "X = digits.images\n",
    "# Normalize the data so that all features lie in (0, 1)\n",
    "X /= np.max(X)\n",
    "y = digits.target\n",
    "plt.imshow(X[0])\n",
    "print(f\"Sample image with label {y[0]}\")\n",
    "print(X.shape)\n",
    "\n",
    "# Reshape input\n",
    "X = X.reshape(-1, 64)\n",
    "# Input size\n",
    "isize = X.shape[-1]\n",
    "# Output size\n",
    "osize = len(np.unique(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def onehot_encoder(y):\n",
    "    k = len(np.unique(y))\n",
    "    return np.eye(k)[y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape: ((1078, 64), (1078, 10))\n",
      "Test data shape: ((719, 64), (719, 10))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# random_state has the same seed value as rng\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                    test_size=0.4,\n",
    "                                                    random_state=seed)\n",
    "Y_train = onehot_encoder(y_train)\n",
    "Y_test = onehot_encoder(y_test)\n",
    "print(f\"Training data shape: {X_train.shape, Y_train.shape}\")\n",
    "print(f\"Test data shape: {X_test.shape, Y_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test-data size = 719\n",
      "Accuracy = 96.24\n",
      "Number of parameters = 2410\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Initialize the network\n",
    "layers = [isize, 32, osize]\n",
    "network = Network(layers, activation_choice='sigmoid',\n",
    "                            output_choice='softmax',\n",
    "                            loss_choice='cce')\n",
    "# Fit the network on the data\n",
    "epochs = 50\n",
    "network.fit(X_train, Y_train, lr=0.01, epochs=epochs, batch_size=10)\n",
    "\n",
    "# Plot the losses\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.plot(range(epochs), network.losses)\n",
    "plt.title(f\"Loss vs Epochs\")\n",
    "plt.xlabel(f\"Epochs\")\n",
    "plt.ylabel(f\"CCE Loss\")\n",
    "\n",
    "# Compute the accuracy\n",
    "accuracy = np.sum(network.predict(X_test) == y_test) / X_test.shape[0] * 100\n",
    "print(f\"Test-data size = {X_test.shape[0]}\")\n",
    "print(f\"Accuracy = {accuracy:.2f}\")\n",
    "print(f\"Number of parameters = {count_params(layers)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
